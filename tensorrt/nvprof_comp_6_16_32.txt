==29189== NVPROF is profiling process 29189, command: ./mbnet
==29189== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==29189== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==29189== Profiling application: ./mbnet
==29189== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   71.11%  517.60ms     10005  51.734us  49.697us  72.801us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                   13.02%  94.807ms     40136  2.3620us     512ns  13.920us  [CUDA memcpy HtoD]
                    6.59%  47.949ms     10025  4.7820us  2.2400us  11.680us  [CUDA memcpy DtoH]
                    4.68%  34.084ms     40090     850ns     640ns  116.00us  [CUDA memset]
                    0.49%  3.5520ms         3  1.1840ms  1.1824ms  1.1853ms  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.15%  1.0958ms         3  365.28us  364.32us  366.72us  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.14%  1.0365ms        10  103.65us  89.921us  120.32us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.14%  1.0022ms        16  62.636us  61.280us  64.480us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.13%  953.31us         5  190.66us  179.36us  230.59us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=4>, fused::KpqkPtrWriter<float, int=1, int=1, int=4>, float, float, int=5, int=3, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.13%  916.90us         7  130.99us  119.01us  159.52us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.11%  802.40us        10  80.240us  75.329us  93.409us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.10%  698.44us        10  69.843us  62.561us  80.161us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.09%  689.79us         4  172.45us  162.40us  196.03us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.09%  673.83us         4  168.46us  160.67us  190.91us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.09%  665.83us         4  166.46us  157.89us  191.39us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.09%  660.93us         4  165.23us  157.12us  189.25us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.09%  658.02us         4  164.50us  155.52us  190.53us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.09%  657.28us         4  164.32us  155.52us  187.68us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.09%  652.93us         3  217.64us  216.77us  218.72us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.09%  644.83us         4  161.21us  152.48us  186.88us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.09%  638.95us         4  159.74us  151.04us  184.16us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.09%  635.24us         4  158.81us  151.52us  179.68us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.09%  632.61us         4  158.15us  149.41us  183.68us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.08%  609.44us         5  121.89us  110.08us  162.88us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=4>, fused::KpqkPtrWriter<float, int=1, int=1, int=4>, float, float, int=5, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.08%  602.59us         4  150.65us  143.23us  171.23us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.08%  601.63us         3  200.54us  196.35us  207.20us  void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensorStruct, float const *, cudnnTensorStruct*)
                    0.08%  597.63us         4  149.41us  143.04us  167.52us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.08%  576.77us         4  144.19us  137.92us  162.56us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.08%  559.20us         4  139.80us  133.76us  157.44us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.08%  552.83us         4  138.21us  129.92us  162.08us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.08%  549.15us         5  109.83us  104.35us  122.53us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.08%  546.31us         4  136.58us  128.96us  159.23us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.07%  538.37us         3  179.46us  175.49us  184.96us  void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)
                    0.07%  531.30us         4  132.82us  124.16us  157.89us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.07%  526.43us         5  105.29us  98.080us  130.59us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  526.21us         4  131.55us  122.88us  156.64us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.07%  506.66us         5  101.33us  88.480us  110.24us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  500.23us         4  125.06us  116.51us  150.08us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.07%  494.47us         5  98.893us  88.161us  117.44us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=4, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  483.20us         4  120.80us  112.96us  143.71us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.07%  480.35us         4  120.09us  114.75us  135.52us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.07%  473.57us         4  118.39us  113.12us  133.60us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.06%  467.87us         8  58.484us  50.400us  80.864us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.06%  448.83us         6  74.805us  29.280us  128.19us  void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)
                    0.06%  446.88us         4  111.72us  106.08us  128.64us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.06%  424.83us        48  8.8500us  8.3200us  9.6000us  [CUDA memcpy DtoD]
                    0.06%  422.72us         4  105.68us  100.35us  121.12us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    0.06%  419.52us         5  83.904us  74.272us  105.09us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  401.73us         5  80.345us  69.952us  94.720us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  365.51us         5  73.101us  69.121us  79.872us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  337.83us         5  67.565us  62.881us  83.232us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  329.86us         5  65.971us  61.248us  82.688us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=6, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  312.00us         5  62.400us  57.920us  72.480us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  302.37us         5  60.473us  57.088us  72.320us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  298.15us         5  59.629us  56.641us  67.040us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.03%  201.66us         3  67.221us  67.072us  67.360us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.03%  201.63us        24  8.4010us  6.8800us  11.040us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.03%  194.75us         3  64.917us  64.640us  65.120us  void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.02%  135.52us         3  45.173us  42.112us  51.200us  void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)
                    0.01%  88.065us         4  22.016us  20.640us  25.761us  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.01%  73.888us         3  24.629us  23.488us  26.560us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
                    0.01%  50.208us         4  12.552us  10.400us  18.208us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
      API calls:   15.91%  13.3831s     50010  267.61us  28.160us  115.73ms  cudaMemcpy
                   12.39%  10.4205s     10003  1.0417ms  83.456us  61.621ms  cudaHostAlloc
                   11.00%  9.25145s    250192  36.977us  1.1840us  1.93704s  cudaFree
                   10.44%  8.78188s     10003  877.93us  48.000us  158.08ms  cudaFreeHost
                    7.69%  6.46737s     30059  215.16us  2.6880us  27.223ms  cudaStreamSynchronize
                    7.56%  6.35656s    130165  48.834us  12.992us  25.874ms  cudaMalloc
                    6.46%  5.43482s     80026  67.913us  7.7440us  3.07259s  cudaMemGetInfo
                    5.18%  4.35681s     80025  54.443us  2.8160us  3.55315s  cudaStreamCreateWithFlags
                    4.15%  3.49319s     10297  339.24us  29.248us  2.43885s  cudaLaunchKernel
                    3.20%  2.69344s    810304  3.3230us     832ns  19.794ms  cudaDeviceGetAttribute
                    2.14%  1.79563s    480141  3.7390us  1.2800us  19.181ms  cudaEventDestroy
                    2.12%  1.78419s    480138  3.7150us  1.3120us  17.293ms  cudaEventCreateWithFlags
                    2.12%  1.78111s       159  11.202ms  7.7440us  186.52ms  cuModuleUnload
                    1.89%  1.59121s     30014  53.015us  27.168us  26.701ms  cudaGetDeviceProperties
                    1.72%  1.44608s    130038  11.120us  3.0720us  18.016ms  cudaStreamDestroy
                    1.61%  1.35775s     40090  33.867us  13.472us  20.240ms  cudaMemsetAsync
                    1.60%  1.34235s     70021  19.170us  3.7760us  18.596ms  cudaDeviceSynchronize
                    0.84%  704.71ms     10021  70.322us  22.144us  13.457ms  cudaCreateTextureObject
                    0.40%  340.35ms     10021  33.963us  7.3280us  11.834ms  cudaDestroyTextureObject
                    0.40%  332.37ms     60026  5.5370us  1.2160us  10.468ms  cudaGetDevice
                    0.25%  213.99ms     10001  21.396us  9.9840us  21.387ms  cudaStreamCreate
                    0.22%  183.17ms     40012  4.5770us  2.6880us  8.7803ms  cudaStreamCreateWithPriority
                    0.19%  162.63ms     10508  15.477us  1.6640us  12.908ms  cudaEventRecord
                    0.14%  118.26ms     50517  2.3410us     448ns  3.7542ms  cudaGetLastError
                    0.11%  96.307ms       233  413.33us  104.06us  14.924ms  cudaEventSynchronize
                    0.09%  73.421ms     10003  7.3390us  4.0000us  1.8347ms  cudaHostGetDevicePointer
                    0.05%  44.073ms     30010  1.4680us     416ns  1.0825ms  cudaGetDeviceCount
                    0.03%  24.164ms     10003  2.4150us  1.6960us  224.96us  cudaDeviceGetStreamPriorityRange
                    0.02%  15.559ms     10021  1.5520us     544ns  1.2950ms  cudaCreateChannelDesc
                    0.02%  15.369ms     10004  1.5360us     416ns  9.0044ms  cudaDriverGetVersion
                    0.02%  14.400ms     20008     719ns     416ns  690.08us  cudaRuntimeGetVersion
                    0.01%  10.753ms       272  39.534us     736ns  515.52us  cudaMemcpyAsync
                    0.01%  7.5129ms       233  32.244us  13.952us  213.02us  cudaStreamAddCallback
                    0.00%  1.3229ms       233  5.6770us  3.9360us  11.808us  cudaEventElapsedTime
                    0.00%  642.59us       568  1.1310us     416ns  48.608us  cuDeviceGetAttribute
                    0.00%  171.01us        60  2.8500us  1.6960us  31.008us  cudaStreamWaitEvent
                    0.00%  86.464us         6  14.410us  7.2960us  19.808us  cuDeviceTotalMem
                    0.00%  30.272us         3  10.090us  9.3120us  10.944us  cudaEventCreate
                    0.00%  24.897us         5  4.9790us  3.7440us  5.8560us  cuInit
                    0.00%  13.568us         8  1.6960us     896ns  3.1040us  cuDeviceGetCount
                    0.00%  13.312us         5  2.6620us  1.6000us  4.1280us  cuDriverGetVersion
                    0.00%  10.720us         6  1.7860us  1.3760us  2.2080us  cuDeviceGetName
                    0.00%  7.7120us         7  1.1010us     832ns  1.7280us  cuDeviceGet
                    0.00%  5.8880us         8     736ns     640ns     864ns  cudaPeekAtLastError
                    0.00%  4.2560us         6     709ns     576ns     800ns  cuDeviceGetUuid
                    0.00%  3.2960us         2  1.6480us  1.5040us  1.7920us  cuDevicePrimaryCtxRelease

==29189== NVTX result:
==29189==   Thread "<unnamed>" (id = 2611339280)
==29189==     Domain "TensorRT"
==29189==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.22155s     10000  122.16us  83.808us  25.918ms  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  517.28ms     10000  51.727us  49.697us  72.801us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  1.03806s     10000  103.81us  71.456us  25.902ms  cudaLaunchKernel

==29189==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  8.47641s     10000  847.64us  194.18us  27.406ms  ExecutionContext::execute
 GPU activities:  100.00%  517.28ms     10000  51.727us  49.697us  72.801us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  1.03806s     10000  103.81us  71.456us  25.902ms  cudaLaunchKernel

==29189== Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.
