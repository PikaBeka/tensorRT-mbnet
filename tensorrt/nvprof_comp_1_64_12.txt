==27011== NVPROF is profiling process 27011, command: ./mbnet
==27011== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==27011== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==27011== Profiling application: ./mbnet
==27011== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   66.45%  1.31596s     10004  131.54us  123.36us  144.64us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                   12.88%  255.14ms     10026  25.448us  1.6640us  473.35us  [CUDA memcpy DtoH]
                    8.38%  165.88ms     20048  8.2740us  5.9520us  515.01us  [CUDA memcpy DtoD]
                    6.87%  135.98ms     40117  3.3890us     480ns  10.720us  [CUDA memcpy HtoD]
                    1.76%  34.864ms     40081     869ns     640ns  452.48us  [CUDA memset]
                    0.68%  13.560ms        27  502.22us  389.76us  580.32us  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.37%  7.3805ms         3  2.4602ms  2.4581ms  2.4622ms  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.15%  2.8730ms        10  287.30us  279.04us  310.11us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.14%  2.6906ms        10  269.06us  252.48us  293.51us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.14%  2.6762ms         5  535.23us  522.63us  580.80us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=4>, fused::KpqkPtrWriter<float, int=1, int=1, int=4>, float, float, int=5, int=3, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.10%  2.0697ms        15  137.98us  97.440us  146.56us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.10%  1.9386ms         3  646.19us  630.24us  669.60us  void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)
                    0.08%  1.6465ms         6  274.42us  267.68us  285.12us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.08%  1.5345ms         5  306.89us  296.99us  317.28us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  1.4763ms         5  295.26us  282.08us  321.44us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  1.4698ms         5  293.97us  265.12us  316.71us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  1.4656ms         3  488.55us  478.88us  502.91us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.07%  1.4608ms         3  486.92us  478.24us  496.61us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.07%  1.4538ms         3  484.59us  475.84us  497.63us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.07%  1.4448ms         3  481.61us  473.76us  495.07us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.07%  1.4291ms         3  476.36us  469.89us  488.16us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.07%  1.4235ms         5  284.71us  279.36us  296.96us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  1.4160ms         3  472.00us  464.48us  486.08us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.07%  1.4014ms         3  467.14us  460.13us  480.48us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.07%  1.3883ms         3  462.75us  454.75us  475.55us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.07%  1.3829ms         5  276.59us  269.35us  297.76us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  1.3338ms         5  266.75us  262.24us  277.76us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  1.0720ms         3  357.32us  350.63us  370.24us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.05%  1.0114ms         4  252.86us  247.84us  266.08us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.05%  997.73us         4  249.43us  244.48us  258.37us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.05%  983.14us         4  245.78us  241.47us  257.31us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.05%  962.43us        27  35.645us  23.200us  61.600us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.05%  954.95us         4  238.74us  230.75us  250.40us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.05%  944.55us         4  236.14us  231.20us  245.31us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.05%  943.04us         4  235.76us  232.13us  244.35us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.05%  928.23us         4  232.06us  228.35us  239.52us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.05%  904.39us         4  226.10us  221.63us  236.03us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.04%  847.36us        27  31.383us  19.360us  50.880us  void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.04%  727.68us         9  80.853us  42.560us  100.64us  void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)
                    0.03%  687.52us         4  171.88us  164.48us  192.64us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.03%  668.07us         4  167.02us  159.39us  187.20us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.03%  645.51us         4  161.38us  153.31us  181.79us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.03%  631.23us         4  157.81us  151.52us  174.11us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.03%  566.75us         4  141.69us  138.75us  148.80us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.03%  564.74us         4  141.18us  137.63us  149.63us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.03%  547.59us         4  136.90us  133.92us  144.83us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.02%  493.95us         6  82.325us  56.160us  104.96us  void fft2d_r2c_64x64<float, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int)
                    0.02%  404.42us         3  134.81us  133.41us  135.68us  void fft2d_c2r_64x64<float, bool=0, bool=1>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)
                    0.02%  378.59us         4  94.648us  92.896us  99.616us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.02%  340.19us         3  113.40us  112.64us  113.79us  void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensorStruct, float const *, cudnnTensorStruct*)
                    0.01%  231.65us        25  9.2650us  7.7120us  11.168us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.01%  129.92us         4  32.480us  27.361us  45.920us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig1DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=1, int=256, int=1, int=64, char=4, bool=1, bool=0, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.01%  106.75us         3  35.584us  24.000us  48.160us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.00%  75.616us         4  18.904us  17.440us  20.960us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.00%  25.760us         3  8.5860us  8.1600us  9.4400us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
      API calls:   16.58%  15.5355s     50010  310.65us  28.576us  122.98ms  cudaMemcpy
                   12.66%  11.8612s     30049  394.73us  2.8160us  35.834ms  cudaStreamSynchronize
                   11.34%  10.6276s     10003  1.0624ms  80.064us  143.01ms  cudaHostAlloc
                   10.04%  9.40274s    260173  36.140us  1.1840us  1.75648s  cudaFree
                    9.27%  8.68321s     10003  868.06us  47.296us  21.005ms  cudaFreeHost
                    7.76%  7.26723s    140146  51.854us  13.856us  27.364ms  cudaMalloc
                    5.34%  5.00368s     80026  62.525us  7.7120us  2.55668s  cudaMemGetInfo
                    4.64%  4.34718s     80025  54.322us  2.9120us  3.49447s  cudaStreamCreateWithFlags
                    3.19%  2.98762s     10318  289.55us  27.008us  2.38879s  cudaLaunchKernel
                    3.00%  2.81413s    810304  3.4720us     800ns  20.935ms  cudaDeviceGetAttribute
                    2.67%  2.50592s     20233  123.85us     928ns  16.578ms  cudaMemcpyAsync
                    2.21%  2.06772s    480141  4.3060us  1.3440us  21.677ms  cudaEventDestroy
                    1.98%  1.85665s    480138  3.8660us  1.3440us  17.010ms  cudaEventCreateWithFlags
                    1.68%  1.57203s     40081  39.221us  14.016us  14.295ms  cudaMemsetAsync
                    1.67%  1.56477s     30014  52.134us  26.368us  13.029ms  cudaGetDeviceProperties
                    1.67%  1.56449s       159  9.8396ms  7.3280us  219.37ms  cuModuleUnload
                    1.55%  1.45636s    130038  11.199us  3.2320us  15.724ms  cudaStreamDestroy
                    1.26%  1.17654s     70021  16.802us  3.7440us  18.525ms  cudaDeviceSynchronize
                    0.44%  412.31ms     60026  6.8680us  1.1200us  13.772ms  cudaGetDevice
                    0.21%  200.44ms     40012  5.0090us  2.9440us  10.016ms  cudaStreamCreateWithPriority
                    0.21%  198.93ms     10001  19.890us  10.688us  11.253ms  cudaStreamCreate
                    0.16%  151.15ms     50487  2.9930us     416ns  10.250ms  cudaGetLastError
                    0.14%  128.78ms       173  744.40us  156.77us  21.328ms  cudaEventSynchronize
                    0.10%  94.887ms     10391  9.1310us  1.6960us  872.19us  cudaEventRecord
                    0.09%  83.002ms     10003  8.2970us  3.6160us  2.0636ms  cudaHostGetDevicePointer
                    0.06%  52.077ms     30010  1.7350us     352ns  6.9389ms  cudaGetDeviceCount
                    0.04%  36.371ms     10003  3.6350us  1.7920us  9.9774ms  cudaDeviceGetStreamPriorityRange
                    0.02%  14.353ms     20008     717ns     320ns  675.36us  cudaRuntimeGetVersion
                    0.02%  14.313ms       173  82.736us  13.728us  1.2750ms  cudaStreamAddCallback
                    0.01%  6.8651ms     10004     686ns     416ns  207.90us  cudaDriverGetVersion
                    0.00%  1.0706ms       173  6.1880us  4.0000us  13.856us  cudaEventElapsedTime
                    0.00%  612.58us       568  1.0780us     416ns  49.216us  cuDeviceGetAttribute
                    0.00%  312.70us        11  28.427us  23.840us  39.520us  cudaCreateTextureObject
                    0.00%  275.94us        87  3.1710us  1.7600us  57.248us  cudaStreamWaitEvent
                    0.00%  131.55us        11  11.959us  10.464us  14.720us  cudaDestroyTextureObject
                    0.00%  82.176us         6  13.696us  6.9440us  20.640us  cuDeviceTotalMem
                    0.00%  78.176us         3  26.058us  6.9120us  60.896us  cudaEventCreate
                    0.00%  47.616us         5  9.5230us  4.1600us  26.048us  cuInit
                    0.00%  13.056us         8  1.6320us     800ns  2.4640us  cuDeviceGetCount
                    0.00%  12.512us         5  2.5020us  1.1840us  4.4160us  cuDriverGetVersion
                    0.00%  10.400us         6  1.7330us  1.1200us  2.4640us  cuDeviceGetName
                    0.00%  9.6960us        11     881ns     608ns  1.7280us  cudaCreateChannelDesc
                    0.00%  8.4480us         7  1.2060us     800ns  1.9840us  cuDeviceGet
                    0.00%  5.0240us         6     837ns     704ns  1.1200us  cuDeviceGetUuid
                    0.00%  4.6400us         7     662ns     544ns     800ns  cudaPeekAtLastError
                    0.00%  4.2560us         2  2.1280us  2.0800us  2.1760us  cuDevicePrimaryCtxRelease

==27011== NVTX result:
==27011==   Thread "<unnamed>" (id = 2509471760)
==27011==     Domain "TensorRT"
==27011==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  799.69ms     10000  79.969us  61.792us  13.538ms  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  1.31546s     10000  131.55us  128.99us  144.64us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
      API calls:  100.00%  584.52ms     10000  58.452us  45.760us  10.675ms  cudaLaunchKernel

==27011==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  8.71808s     10000  871.81us  318.56us  16.709ms  ExecutionContext::execute
 GPU activities:   94.76%  1.31546s     10000  131.55us  128.99us  144.64us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    5.24%  72.785ms     10000  7.2780us  6.2720us  10.880us  [CUDA memcpy DtoD]
      API calls:   57.38%  786.88ms     10000  78.688us  49.888us  13.960ms  cudaMemcpyAsync
                   42.62%  584.52ms     10000  58.452us  45.760us  10.675ms  cudaLaunchKernel

==27011== Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.
