==25101== NVPROF is profiling process 25101, command: ./mbnet
==25101== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==25101== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==25101== Profiling application: ./mbnet
==25101== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   67.91%  347.70ms     10005  34.752us  18.752us  50.241us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                   15.05%  77.055ms     40136  1.9190us     352ns  13.440us  [CUDA memcpy HtoD]
                    6.83%  34.948ms     40090     871ns     480ns  113.06us  [CUDA memset]
                    4.06%  20.768ms     10025  2.0710us  1.4720us  12.545us  [CUDA memcpy DtoH]
                    0.69%  3.5527ms         3  1.1842ms  1.1824ms  1.1862ms  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.27%  1.4017ms         5  280.33us  237.06us  319.36us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=4>, fused::KpqkPtrWriter<float, int=1, int=1, int=4>, float, float, int=5, int=3, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.21%  1.0968ms         3  365.61us  363.88us  368.32us  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.17%  890.70us         7  127.24us  114.40us  157.79us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.17%  852.20us        16  53.262us  51.969us  55.041us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.14%  704.10us        10  70.410us  55.264us  87.777us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.13%  685.51us         4  171.38us  161.47us  200.35us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.13%  673.73us         4  168.43us  159.68us  193.35us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.13%  662.41us         4  165.60us  156.00us  192.55us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.13%  660.61us         4  165.15us  156.16us  191.27us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.13%  656.49us         4  164.12us  154.72us  189.76us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.13%  653.26us         4  163.31us  154.21us  190.08us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.13%  648.45us         3  216.15us  215.20us  217.51us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.13%  643.65us         4  160.91us  151.27us  188.48us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.12%  633.93us         4  158.48us  150.72us  180.96us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.12%  633.28us         4  158.32us  150.56us  180.58us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.12%  630.92us         4  157.73us  146.40us  187.36us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.12%  625.86us         5  125.17us  115.20us  162.24us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=4>, fused::KpqkPtrWriter<float, int=1, int=1, int=4>, float, float, int=5, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.12%  596.61us         4  149.15us  142.21us  169.76us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.12%  595.59us         3  198.53us  193.76us  206.72us  void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensorStruct, float const *, cudnnTensorStruct*)
                    0.12%  592.01us         4  148.00us  140.80us  167.52us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.11%  581.51us         5  116.30us  107.59us  147.27us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.11%  571.62us         4  142.91us  135.30us  164.96us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.11%  560.96us         4  140.24us  131.49us  158.11us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.11%  548.58us        10  54.858us  48.832us  77.280us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.11%  544.77us         4  136.19us  128.16us  159.52us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.11%  538.28us         4  134.57us  124.64us  163.43us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.10%  525.13us         4  131.28us  122.24us  157.76us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.10%  518.15us         4  129.54us  119.36us  159.23us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.10%  494.56us         4  123.64us  115.68us  147.20us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.10%  493.83us         5  98.765us  89.121us  135.17us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=4, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.10%  493.06us         4  123.26us  112.48us  145.44us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.09%  473.70us         4  118.43us  112.55us  135.36us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.09%  464.87us         4  116.22us  110.24us  133.63us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.09%  455.36us         6  75.894us  25.600us  121.25us  void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)
                    0.09%  454.95us         5  90.989us  74.241us  151.20us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.09%  442.75us         4  110.69us  104.35us  128.48us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.09%  439.17us        10  43.917us  39.361us  61.120us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.09%  437.73us         8  54.716us  46.881us  77.121us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.08%  435.07us        48  9.0640us  8.1600us  9.8880us  [CUDA memcpy DtoD]
                    0.08%  420.96us         4  105.24us  99.201us  122.72us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    0.07%  379.62us         3  126.54us  115.68us  148.16us  void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)
                    0.06%  319.97us         5  63.994us  58.113us  85.409us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  310.72us         5  62.144us  54.145us  88.577us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  293.38us         5  58.675us  53.921us  75.937us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=6, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  262.95us         5  52.589us  48.224us  68.481us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  260.39us         5  52.077us  47.744us  67.264us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  244.67us        24  10.194us  9.6000us  10.656us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.05%  231.27us         5  46.253us  42.176us  60.800us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=5, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  220.67us         5  44.134us  39.457us  60.001us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  215.30us         5  43.059us  39.520us  55.905us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  189.38us         3  63.126us  62.881us  63.296us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.04%  188.23us         3  62.741us  61.600us  63.745us  void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.03%  162.11us         5  32.422us  28.800us  45.856us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.02%  96.322us         3  32.107us  28.801us  38.561us  void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)
                    0.01%  71.168us         3  23.722us  22.880us  24.928us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
                    0.01%  43.680us         4  10.920us  9.0560us  16.320us  void genericReformat::copyPackedKernel<float, float, bool=0, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.01%  42.752us         4  10.688us  8.9600us  15.680us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
      API calls:   18.73%  11.2334s     50010  224.62us  29.824us  116.28ms  cudaMemcpy
                   11.56%  6.93236s    250192  27.708us  1.2480us  1.25821s  cudaFree
                   10.44%  6.26227s     10003  626.04us  155.75us  46.770ms  cudaHostAlloc
                    8.12%  4.87074s    130165  37.419us  13.760us  2.4476ms  cudaMalloc
                    7.35%  4.40975s     80026  55.103us  7.6170us  2.39684s  cudaMemGetInfo
                    6.29%  3.77396s     30059  125.55us  2.6880us  14.026ms  cudaStreamSynchronize
                    6.14%  3.68416s     10003  368.31us  77.632us  5.7077ms  cudaFreeHost
                    5.53%  3.31382s     80025  41.409us  3.0400us  2.71475s  cudaStreamCreateWithFlags
                    4.95%  2.97082s     10297  288.51us  32.288us  2.03909s  cudaLaunchKernel
                    3.73%  2.23484s    810304  2.7580us     832ns  4.1747ms  cudaDeviceGetAttribute
                    2.67%  1.59824s       159  10.052ms  9.1200us  182.73ms  cuModuleUnload
                    2.24%  1.34326s    480141  2.7970us  1.3440us  2.5274ms  cudaEventDestroy
                    2.22%  1.32873s     30014  44.270us  27.456us  2.4493ms  cudaGetDeviceProperties
                    2.20%  1.31633s    480138  2.7410us  1.3760us  3.6560ms  cudaEventCreateWithFlags
                    1.83%  1.09851s     40090  27.401us  13.952us  4.1235ms  cudaMemsetAsync
                    1.60%  959.69ms    130038  7.3800us  3.2640us  5.6246ms  cudaStreamDestroy
                    1.56%  936.56ms     70021  13.375us  3.9360us  3.1836ms  cudaDeviceSynchronize
                    0.95%  570.37ms     10021  56.917us  29.153us  4.4600ms  cudaCreateTextureObject
                    0.37%  220.81ms     60026  3.6780us  1.2480us  732.20us  cudaGetDevice
                    0.28%  166.15ms     40012  4.1520us  2.8800us  536.96us  cudaStreamCreateWithPriority
                    0.25%  149.47ms     10001  14.945us  10.592us  715.43us  cudaStreamCreate
                    0.22%  134.28ms     10021  13.399us  8.4160us  1.5512ms  cudaDestroyTextureObject
                    0.17%  101.90ms     10508  9.6970us  1.6960us  1.1118ms  cudaEventRecord
                    0.14%  84.585ms       233  363.02us  71.777us  3.8991ms  cudaEventSynchronize
                    0.12%  70.010ms     50517  1.3850us     416ns  680.96us  cudaGetLastError
                    0.11%  67.614ms     10003  6.7590us  4.0960us  695.68us  cudaHostGetDevicePointer
                    0.08%  44.992ms     30010  1.4990us     416ns  1.1609ms  cudaGetDeviceCount
                    0.04%  23.106ms     10003  2.3090us  1.7600us  72.640us  cudaDeviceGetStreamPriorityRange
                    0.03%  20.113ms       272  73.945us     864ns  507.30us  cudaMemcpyAsync
                    0.02%  13.367ms     20008     668ns     416ns  722.37us  cudaRuntimeGetVersion
                    0.02%  13.208ms     10021  1.3170us     480ns  250.98us  cudaCreateChannelDesc
                    0.01%  7.4635ms     10004     746ns     416ns  122.18us  cudaDriverGetVersion
                    0.01%  6.2865ms       233  26.980us  13.152us  187.36us  cudaStreamAddCallback
                    0.00%  1.4884ms       233  6.3870us  3.8400us  13.472us  cudaEventElapsedTime
                    0.00%  683.62us       568  1.2030us     416ns  57.185us  cuDeviceGetAttribute
                    0.00%  149.09us        60  2.4840us  1.7920us  5.2160us  cudaStreamWaitEvent
                    0.00%  85.761us         6  14.293us  7.3600us  20.225us  cuDeviceTotalMem
                    0.00%  39.616us         3  13.205us  11.008us  14.592us  cudaEventCreate
                    0.00%  26.336us         5  5.2670us  4.4800us  6.5920us  cuInit
                    0.00%  14.560us         8  1.8200us     960ns  3.5520us  cuDeviceGetCount
                    0.00%  13.312us         5  2.6620us  1.4080us  4.2560us  cuDriverGetVersion
                    0.00%  10.848us         6  1.8080us  1.1520us  2.3360us  cuDeviceGetName
                    0.00%  7.7760us         7  1.1100us     928ns  1.6960us  cuDeviceGet
                    0.00%  5.8880us         8     736ns     576ns  1.0240us  cudaPeekAtLastError
                    0.00%  4.5120us         6     752ns     640ns     960ns  cuDeviceGetUuid
                    0.00%  3.9040us         2  1.9520us  1.5680us  2.3360us  cuDevicePrimaryCtxRelease

==25101== NVTX result:
==25101==   Thread "<unnamed>" (id = 2471108624)
==25101==     Domain "TensorRT"
==25101==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.05586s     10000  105.59us  84.513us  2.1176ms  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  347.54ms     10000  34.753us  18.752us  50.241us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  915.35ms     10000  91.535us  73.280us  2.1015ms  cudaLaunchKernel

==25101==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.41955s     10000  541.95us  175.78us  14.242ms  ExecutionContext::execute
 GPU activities:  100.00%  347.54ms     10000  34.753us  18.752us  50.241us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=3, int=2, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  915.35ms     10000  91.535us  73.280us  2.1015ms  cudaLaunchKernel

==25101== Warning: Some profiling data are not recorded. Make sure cudaProfilerStop() or cuProfilerStop() is called before application exit to flush profile data.
