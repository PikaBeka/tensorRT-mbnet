==27894== NVPROF is profiling process 27894, command: ./mbnet
==27894== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==27894== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==27894== Profiling application: ./mbnet
==27894== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   71.67%  1.07198s     10005  107.14us  23.521us  126.72us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                   13.08%  195.56ms     40114  4.8750us     320ns  13.696us  [CUDA memcpy HtoD]
                    8.28%  123.85ms     10025  12.354us  2.7200us  14.944us  [CUDA memcpy DtoH]
                    5.44%  81.371ms     40079  2.0300us     960ns  15.200us  [CUDA memset]
                    0.12%  1.7479ms         3  582.63us  580.04us  586.24us  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.07%  1.0562ms        17  62.129us  61.313us  64.609us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.06%  969.48us         3  323.16us  320.64us  326.43us  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.06%  919.11us        10  91.911us  29.568us  186.72us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  885.45us        10  88.544us  31.648us  113.25us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  843.05us         5  168.61us  153.03us  195.71us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  794.18us         4  198.55us  192.77us  213.73us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.05%  793.48us         4  198.37us  190.21us  215.87us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.05%  786.57us         4  196.64us  191.68us  209.12us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.05%  772.23us         4  193.06us  185.12us  208.99us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.05%  767.05us         4  191.76us  185.12us  206.24us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.05%  753.25us         4  188.31us  183.36us  202.69us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.05%  748.52us         4  187.13us  180.83us  200.19us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.05%  739.46us         4  184.87us  179.71us  199.39us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.05%  735.94us         5  147.19us  137.57us  164.35us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  642.63us         5  128.53us  121.51us  150.98us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.04%  576.13us         4  144.03us  137.12us  162.85us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.04%  547.11us         7  78.158us  76.160us  84.673us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.03%  432.35us         4  108.09us  101.95us  121.60us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.03%  428.20us         4  107.05us  102.56us  120.32us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.03%  422.82us         4  105.71us  100.64us  117.73us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.03%  403.04us         4  100.76us  94.880us  111.07us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.03%  399.65us         4  99.913us  95.841us  108.00us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.03%  399.27us         4  99.817us  96.833us  107.52us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.03%  390.37us         4  97.593us  94.369us  105.28us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.03%  385.73us         4  96.432us  93.729us  101.95us  void cudnn::cnn::conv2d_grouped_direct_kernel<bool=0, bool=1, bool=0, bool=0, int=0, int=0, int, float, float, float, float, float, float>(cudnn::cnn::GroupedDirectFpropParams, float const *, float const *, float*, float, float*, float const * const *, float const *, cudnnActivationStruct)
                    0.03%  375.17us         4  93.792us  89.280us  101.60us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.02%  344.04us         4  86.009us  76.801us  109.60us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.02%  340.83us         4  85.208us  76.000us  111.36us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.02%  317.15us         4  79.288us  71.233us  101.12us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.02%  311.08us         4  77.769us  69.441us  98.401us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.02%  264.52us         6  44.085us  37.120us  59.073us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.02%  263.97us         4  65.992us  63.328us  73.281us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.02%  261.03us         4  65.256us  61.153us  73.473us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.02%  257.09us        48  5.3560us  4.8000us  7.3600us  [CUDA memcpy DtoD]
                    0.02%  254.31us         4  63.576us  60.768us  70.848us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.02%  242.88us         4  60.720us  57.601us  69.121us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    0.02%  239.84us         6  39.973us  32.480us  53.921us  void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.01%  198.56us        24  8.2730us  7.2000us  10.880us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.01%  181.79us         4  45.448us  38.816us  64.513us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig1DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=1, int=256, int=1, int=64, char=4, bool=1, bool=0, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.01%  150.72us         5  30.144us  25.920us  32.992us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.01%  149.25us         5  29.850us  27.041us  39.200us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.01%  102.08us         3  34.026us  28.480us  44.960us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.01%  99.969us         3  33.323us  27.968us  44.001us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.01%  85.152us         4  21.288us  19.680us  25.120us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.01%  82.978us         4  20.744us  17.473us  30.144us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.00%  21.440us         3  7.1460us  6.0800us  9.1200us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
      API calls:   21.73%  13.0540s     80026  163.12us  7.6160us  11.3885s  cudaMemGetInfo
                   11.78%  7.07737s    250170  28.290us  1.2160us  1.47763s  cudaFree
                   10.48%  6.29689s     10003  629.50us  80.032us  3.3368ms  cudaHostAlloc
                    7.81%  4.68891s    130143  36.028us  14.304us  2.6583ms  cudaMalloc
                    7.07%  4.24538s     50010  84.890us  28.768us  115.02ms  cudaMemcpy
                    6.44%  3.87112s     10003  387.00us  45.088us  1.8439ms  cudaFreeHost
                    6.41%  3.85074s     80025  48.119us  2.9120us  3.27161s  cudaStreamCreateWithFlags
                    4.75%  2.85490s     10241  278.77us  31.200us  1.98039s  cudaLaunchKernel
                    3.50%  2.09990s    810304  2.5910us     512ns  4.1522ms  cudaDeviceGetAttribute
                    3.15%  1.89055s       159  11.890ms  9.1200us  238.96ms  cuModuleUnload
                    3.14%  1.88865s     30048  62.854us  2.7520us  10.629ms  cudaStreamSynchronize
                    2.17%  1.30361s    480141  2.7150us  1.3120us  833.77us  cudaEventDestroy
                    2.11%  1.26717s    480138  2.6390us  1.3760us  1.4971ms  cudaEventCreateWithFlags
                    2.08%  1.24729s     30014  41.557us  26.464us  700.96us  cudaGetDeviceProperties
                    1.77%  1.06020s     40079  26.452us  13.760us  685.06us  cudaMemsetAsync
                    1.52%  913.33ms    130038  7.0230us  3.1040us  315.55us  cudaStreamDestroy
                    1.37%  821.64ms     70021  11.734us  3.8080us  776.45us  cudaDeviceSynchronize
                    0.89%  536.89ms     10010  53.635us  29.248us  1.2250ms  cudaCreateTextureObject
                    0.34%  205.30ms     60026  3.4200us  1.2480us  690.02us  cudaGetDevice
                    0.27%  165.00ms     40012  4.1230us  2.6880us  347.33us  cudaStreamCreateWithPriority
                    0.26%  154.29ms     10010  15.413us  7.4880us  734.72us  cudaDestroyTextureObject
                    0.22%  134.18ms     10001  13.417us  10.304us  652.16us  cudaStreamCreate
                    0.16%  96.280ms       179  537.88us  11.424us  8.4569ms  cudaEventSynchronize
                    0.15%  91.974ms     10400  8.8430us  1.7600us  658.98us  cudaEventRecord
                    0.12%  73.293ms     50407  1.4540us     416ns  643.04us  cudaGetLastError
                    0.11%  63.261ms     10003  6.3240us  3.3920us  658.76us  cudaHostGetDevicePointer
                    0.06%  38.663ms     30010  1.2880us     416ns  824.90us  cudaGetDeviceCount
                    0.04%  24.318ms     10003  2.4310us  1.8560us  111.01us  cudaDeviceGetStreamPriorityRange
                    0.02%  13.246ms     20008     662ns     416ns  621.19us  cudaRuntimeGetVersion
                    0.02%  12.802ms     10010  1.2780us     544ns  106.85us  cudaCreateChannelDesc
                    0.02%  9.5257ms       228  41.779us     896ns  239.30us  cudaMemcpyAsync
                    0.01%  6.7649ms     10004     676ns     448ns  47.041us  cudaDriverGetVersion
                    0.01%  5.3098ms       179  29.663us  13.504us  172.16us  cudaStreamAddCallback
                    0.00%  1.3080ms       179  7.3070us  4.0000us  34.817us  cudaEventElapsedTime
                    0.00%  665.38us       568  1.1710us     448ns  59.457us  cuDeviceGetAttribute
                    0.00%  150.50us        60  2.5080us  1.8240us  5.9520us  cudaStreamWaitEvent
                    0.00%  90.432us         6  15.072us  7.8720us  19.424us  cuDeviceTotalMem
                    0.00%  31.456us         3  10.485us  7.5520us  14.880us  cudaEventCreate
                    0.00%  26.624us         5  5.3240us  4.2880us  6.4000us  cuInit
                    0.00%  15.968us         8  1.9960us  1.1200us  3.4880us  cuDeviceGetCount
                    0.00%  15.936us         5  3.1870us  1.7600us  4.7360us  cuDriverGetVersion
                    0.00%  11.744us         6  1.9570us  1.3440us  2.4640us  cuDeviceGetName
                    0.00%  7.6800us         7  1.0970us     800ns  1.5360us  cuDeviceGet
                    0.00%  6.2400us         8     780ns     672ns  1.1840us  cudaPeekAtLastError
                    0.00%  4.5760us         6     762ns     640ns     896ns  cuDeviceGetUuid
                    0.00%  4.5120us         2  2.2560us  1.9840us  2.5280us  cuDevicePrimaryCtxRelease

==27894== NVTX result:
==27894==   Thread "<unnamed>" (id = 2260983824)
==27894==     Domain "TensorRT"
==27894==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  999.78ms     10000  99.978us  85.408us  785.70us  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  1.07185s     10000  107.18us  56.320us  126.72us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  861.17ms     10000  86.117us  73.888us  722.34us  cudaLaunchKernel

==27894==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  3.39607s     10000  339.61us  210.82us  10.809ms  ExecutionContext::execute
 GPU activities:  100.00%  1.07185s     10000  107.18us  56.320us  126.72us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  861.17ms     10000  86.117us  73.888us  722.34us  cudaLaunchKernel

