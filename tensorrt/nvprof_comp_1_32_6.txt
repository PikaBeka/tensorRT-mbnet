==8145== NVPROF is profiling process 8145, command: ./mbnet
==8145== Warning: Unified Memory Profiling is not supported on the underlying platform. System requirements for unified memory can be found at: http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
==8145== Warning: Profiling results might be incorrect with current version of nvcc compiler used to compile cuda app. Compile with nvcc compiler 9.0 or later version to get correct profiling results. Ignore this warning if code is already compiled with the recommended nvcc version 
==8145== Profiling application: ./mbnet
==8145== Profiling result:
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
 GPU activities:   69.65%  437.37ms     10010  43.693us  34.753us  73.216us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                   13.60%  85.410ms     40114  2.1290us     512ns  5.1200us  [CUDA memcpy HtoD]
                    7.87%  49.439ms     10025  4.9310us  2.7200us  9.2800us  [CUDA memcpy DtoH]
                    5.43%  34.078ms     40079     850ns     640ns  16.576us  [CUDA memset]
                    0.28%  1.7502ms         3  583.39us  569.61us  607.11us  void gemv2N_kernel<int, int, float2, float2, float2, int=128, int=8, int=4, int=4, int=1, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const )
                    0.17%  1.0686ms        17  62.859us  61.600us  66.081us  void op_generic_tensor_kernel<int=3, float, float, float, int=256, cudnnGenericOp_t=0, cudnnNanPropagation_t=0, int=0>(cudnnTensorStruct, float*, cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, float, float, float, cudnnActivationStruct, reducedDivisorArray, int)
                    0.15%  971.02us         3  323.67us  321.60us  326.63us  void gemv2T_kernel_val<int, int, float2, float2, float2, int=128, int=16, int=2, int=2, bool=0, cublasGemvParams<cublasGemvTensorStridedBatched<float2 const >, cublasGemvTensorStridedBatched<float2>, float2>>(float2 const , float2, float2)
                    0.13%  836.78us        10  83.677us  71.904us  101.44us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.13%  796.42us         4  199.11us  192.96us  213.12us  trt_maxwell_scudnn_128x128_relu_large_nn_v0
                    0.13%  793.61us         4  198.40us  191.52us  214.72us  trt_maxwell_scudnn_128x128_relu_medium_nn_v0
                    0.13%  789.00us         4  197.25us  191.52us  212.19us  trt_maxwell_scudnn_128x128_relu_small_nn_v0
                    0.12%  775.40us         4  193.85us  184.48us  213.22us  trt_maxwell_scudnn_128x128_relu_interior_nn_v0
                    0.12%  767.75us         4  191.94us  185.31us  207.55us  trt_maxwell_scudnn_128x128_relu_large_nn_v1
                    0.12%  766.41us         4  191.60us  184.00us  208.80us  trt_maxwell_scudnn_128x128_relu_medium_nn_v1
                    0.12%  763.78us         4  190.95us  178.24us  227.84us  trt_maxwell_scudnn_128x128_relu_interior_nn_v1
                    0.12%  751.37us         4  187.84us  183.30us  200.23us  trt_maxwell_scudnn_128x128_relu_small_nn_v1
                    0.09%  582.31us         4  145.58us  137.92us  167.11us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=1, unsigned char=0, bool=0, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig2DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=2, int=64, int=64, int=256, char=4, bool=0, bool=1, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.09%  545.64us         7  77.948us  72.641us  83.265us  void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=0, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)
                    0.07%  452.39us         5  90.477us  80.641us  116.48us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=3, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.07%  434.50us         4  108.63us  103.11us  121.86us  trt_maxwell_scudnn_128x64_relu_medium_nn_v1
                    0.07%  429.67us         4  107.42us  101.44us  120.07us  trt_maxwell_scudnn_128x64_relu_large_nn_v1
                    0.07%  421.22us         4  105.31us  100.80us  114.37us  trt_maxwell_scudnn_128x64_relu_small_nn_v1
                    0.06%  403.59us         4  100.90us  94.625us  116.16us  trt_maxwell_scudnn_128x64_relu_interior_nn_v1
                    0.06%  401.48us         4  100.37us  96.033us  109.92us  trt_maxwell_scudnn_128x64_relu_large_nn_v0
                    0.06%  398.66us         4  99.665us  96.065us  109.22us  trt_maxwell_scudnn_128x64_relu_medium_nn_v0
                    0.06%  387.91us         4  96.977us  91.521us  107.04us  trt_maxwell_scudnn_128x64_relu_small_nn_v0
                    0.06%  379.81us         4  94.953us  89.441us  104.48us  trt_maxwell_scudnn_128x64_relu_interior_nn_v0
                    0.06%  379.17us         4  94.793us  93.505us  98.145us  void cudnn::cnn::conv2d_grouped_direct_kernel<bool=0, bool=1, bool=0, bool=0, int=0, int=0, int, float, float, float, float, float, float>(cudnn::cnn::GroupedDirectFpropParams, float const *, float const *, float*, float, float*, float const * const *, float const *, cudnnActivationStruct)
                    0.06%  366.82us         5  73.364us  66.529us  92.641us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=5, int=2, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  361.13us         5  72.225us  65.057us  84.321us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=2>, fused::KpqkPtrWriter<float, int=1, int=1, int=2>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  347.94us         5  69.588us  63.777us  91.297us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=5, int=5, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.06%  346.88us         4  86.720us  77.120us  114.40us  trt_maxwell_scudnn_128x32_relu_large_nn_v1
                    0.05%  343.59us         4  85.896us  75.361us  107.59us  trt_maxwell_scudnn_128x32_relu_medium_nn_v1
                    0.05%  343.08us         5  68.615us  65.121us  73.761us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=2, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  334.63us         5  66.925us  64.641us  70.753us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=3, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
                    0.05%  313.41us         4  78.352us  69.985us  101.76us  trt_maxwell_scudnn_128x32_relu_small_nn_v1
                    0.05%  312.61us         4  78.152us  69.696us  101.38us  trt_maxwell_scudnn_128x32_relu_interior_nn_v1
                    0.05%  282.72us         6  47.120us  36.000us  75.841us  void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)
                    0.04%  274.34us        48  5.7150us  4.8000us  7.4240us  [CUDA memcpy DtoD]
                    0.04%  265.09us         4  66.273us  62.465us  75.361us  trt_maxwell_scudnn_128x32_relu_medium_nn_v0
                    0.04%  263.08us         4  65.769us  62.337us  74.017us  trt_maxwell_scudnn_128x32_relu_large_nn_v0
                    0.04%  259.24us         4  64.809us  61.537us  73.921us  trt_maxwell_scudnn_128x32_relu_small_nn_v0
                    0.04%  258.34us         6  43.056us  32.640us  70.176us  void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.04%  247.39us         4  61.848us  58.560us  71.681us  trt_maxwell_scudnn_128x32_relu_interior_nn_v0
                    0.03%  219.56us        24  9.1480us  7.2640us  11.744us  void cask_trt::computeOffsetsKernel<bool=0, bool=0>(cask_trt::ComputeOffsetsParams)
                    0.02%  111.91us         3  37.301us  27.201us  56.384us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.02%  103.14us         4  25.784us  20.256us  40.800us  void CUTENSOR_NAMESPACE::permutationKernelPLC3<CUTENSOR_NAMESPACE::VectorWrite2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::VectorRead2DTensorView<unsigned char=0, unsigned char=1, bool=1, unsigned int=4, float, float, CUTENSOR_NAMESPACE::GeneralUnarySmall<float>>, CUTENSOR_NAMESPACE::ThreadLevelElementwise<CUTENSOR_NAMESPACE::ElementwiseConfig1DCommonCase<CUTENSOR_NAMESPACE::GeneralUnarySmall<float>, CUTENSOR_NAMESPACE::GeneralBinary<float>, int=1, int=256, int=1, int=64, char=4, bool=1, bool=0, bool=1, bool=1, bool=0>, float>, CUTENSOR_NAMESPACE::ElementwiseRuntimePLC3<float, float, float, float>::Params>(unsigned int=4)
                    0.02%  100.96us         3  33.653us  27.840us  44.480us  void fft2d_r2c_32x32<float, bool=0, unsigned int=5, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)
                    0.01%  86.080us         4  21.520us  19.680us  26.144us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::IdentityCoordMapper<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::IdentityCoordMapper<int=4>>, genericReformat::ArrayN, int, int, int, float const *, void*, genericReformat::ArrayN, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayN, int, int, int, float const , int=4)
                    0.01%  46.944us         4  11.736us  9.2800us  18.784us  void genericReformat::copyPackedKernel<float, float, bool=1, bool=1, genericReformat::ArrayN<int=4>, int=4>(unsigned int, unsigned int, void const *, genericReformat::ArrayN<genericReformat::ArrayN<int=4>>, genericReformat::ArrayNWithReducedDivisors<genericReformat::ArrayN<int=4>>, void const *, int, int, int, float const *, void*, void const *, genericReformat::ArrayNWithReducedDivisors, genericReformat::ArrayNWithReducedDivisors, void const *, int, int, int, float const , int=4)
                    0.00%  21.760us         3  7.2530us  5.9200us  9.6000us  void flip_filter<float, float>(float*, float const *, int, int, int, int)
      API calls:   19.50%  11.9562s     50010  239.08us  28.928us  117.43ms  cudaMemcpy
                   11.70%  7.17351s    250170  28.674us  1.2800us  1.26766s  cudaFree
                   10.02%  6.14458s     10003  614.27us  78.817us  16.176ms  cudaHostAlloc
                    8.19%  5.02190s    130143  38.587us  13.953us  2.4231ms  cudaMalloc
                    7.00%  4.29103s     80026  53.620us  7.5520us  2.37297s  cudaMemGetInfo
                    6.47%  3.96960s     30048  132.11us  2.8160us  10.197ms  cudaStreamSynchronize
                    6.19%  3.79207s     10003  379.09us  42.976us  2.5747ms  cudaFreeHost
                    5.41%  3.31831s     80025  41.465us  2.9770us  2.70493s  cudaStreamCreateWithFlags
                    4.81%  2.95072s     10241  288.13us  32.192us  2.02511s  cudaLaunchKernel
                    3.67%  2.25076s    810304  2.7770us     576ns  4.1956ms  cudaDeviceGetAttribute
                    2.63%  1.61437s       159  10.153ms  9.1200us  187.99ms  cuModuleUnload
                    2.26%  1.38693s    480141  2.8880us  1.3440us  1.1212ms  cudaEventDestroy
                    2.18%  1.33487s    480138  2.7800us  1.4400us  1.7825ms  cudaEventCreateWithFlags
                    2.14%  1.31020s     30014  43.652us  27.424us  744.04us  cudaGetDeviceProperties
                    1.78%  1.09159s     40079  27.235us  13.984us  670.92us  cudaMemsetAsync
                    1.62%  992.45ms    130038  7.6310us  3.4560us  1.0902ms  cudaStreamDestroy
                    1.56%  956.58ms     70021  13.661us  3.9680us  3.1343ms  cudaDeviceSynchronize
                    0.93%  570.40ms     10010  56.982us  33.152us  3.2423ms  cudaCreateTextureObject
                    0.37%  224.51ms     60026  3.7400us  1.3760us  884.20us  cudaGetDevice
                    0.30%  183.87ms     10010  18.368us  9.2800us  1.7671ms  cudaDestroyTextureObject
                    0.28%  173.29ms     40012  4.3300us  3.0400us  373.16us  cudaStreamCreateWithPriority
                    0.24%  150.14ms     10001  15.012us  10.817us  748.61us  cudaStreamCreate
                    0.16%  99.613ms     10400  9.5780us  1.7600us  715.24us  cudaEventRecord
                    0.14%  83.578ms     50407  1.6580us     416ns  762.57us  cudaGetLastError
                    0.11%  70.397ms     10003  7.0370us  3.9680us  651.53us  cudaHostGetDevicePointer
                    0.11%  69.571ms       179  388.67us  12.864us  3.6325ms  cudaEventSynchronize
                    0.07%  44.543ms     30010  1.4840us     448ns  659.24us  cudaGetDeviceCount
                    0.04%  24.084ms     10003  2.4070us  1.8560us  93.313us  cudaDeviceGetStreamPriorityRange
                    0.03%  16.521ms       228  72.458us     960ns  491.88us  cudaMemcpyAsync
                    0.02%  13.871ms     20008     693ns     416ns  797.86us  cudaRuntimeGetVersion
                    0.02%  12.515ms     10010  1.2500us     608ns  63.872us  cudaCreateChannelDesc
                    0.01%  6.5471ms     10004     654ns     448ns  58.241us  cudaDriverGetVersion
                    0.01%  5.2123ms       179  29.118us  13.600us  193.99us  cudaStreamAddCallback
                    0.00%  1.2619ms       179  7.0490us  3.8400us  14.144us  cudaEventElapsedTime
                    0.00%  699.27us       568  1.2310us     448ns  71.617us  cuDeviceGetAttribute
                    0.00%  162.98us        60  2.7160us  1.8560us  7.0080us  cudaStreamWaitEvent
                    0.00%  93.056us         6  15.509us  6.7200us  23.648us  cuDeviceTotalMem
                    0.00%  41.056us         3  13.685us  7.2320us  17.888us  cudaEventCreate
                    0.00%  28.800us         5  5.7600us  4.5120us  6.7840us  cuInit
                    0.00%  16.256us         8  2.0320us     960ns  5.0880us  cuDeviceGetCount
                    0.00%  13.600us         5  2.7200us  1.9520us  4.5760us  cuDriverGetVersion
                    0.00%  11.744us         6  1.9570us  1.2160us  2.9440us  cuDeviceGetName
                    0.00%  10.656us         7  1.5220us     928ns  3.0400us  cuDeviceGet
                    0.00%  6.7840us         8     848ns     672ns  1.1840us  cudaPeekAtLastError
                    0.00%  4.5760us         2  2.2880us  1.9520us  2.6240us  cuDevicePrimaryCtxRelease
                    0.00%  4.0640us         6     677ns     608ns     768ns  cuDeviceGetUuid

==8145== NVTX result:
==8145==   Thread "<unnamed>" (id = 2717016080)
==8145==     Domain "TensorRT"
==8145==       Range "(Unnamed Layer* 0) [Convolution]"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  1.06146s     10000  106.15us  85.601us  1.6479ms  (Unnamed Layer* 0) [Convolution]
 GPU activities:  100.00%  436.83ms     10000  43.683us  34.753us  73.216us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  912.34ms     10000  91.233us  73.601us  1.6240ms  cudaLaunchKernel

==8145==       Range "ExecutionContext::execute"
            Type  Time(%)      Time     Calls       Avg       Min       Max  Name
          Range:  100.00%  5.61795s     10000  561.79us  183.20us  10.368ms  ExecutionContext::execute
 GPU activities:  100.00%  436.83ms     10000  43.683us  34.753us  73.216us  void fused::fusedConvolutionReluKernel<fused::SrcChwcPtr_FltTex_Reader<float, int=1, int=1, int=1, int=1>, fused::KpqkPtrWriter<float, int=1, int=1, int=1>, float, float, int=4, int=4, int=1, int=5, int=5, int=1, int=1>(fused::ConvolutionParams<floatSrcType, int=1, int=1Type>)
      API calls:  100.00%  912.34ms     10000  91.233us  73.601us  1.6240ms  cudaLaunchKernel

